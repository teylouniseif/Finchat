Algorithmic steps to extract information from PDF

1)  Use OCR library to convert PDF into corresponding text(pdfplumber is a good choice)

2)  Use algorithm to attach sections of text to corresponding title/subtitle, by 

    a-using regex division using separators like \n and \t

    or

    b-using spatial coordinates to relate titles to their sections.
    Libraries like pdfplumber offer spatial information about text blocks

    Regardles of the two approaches, given the following layout:

    ###
    Note 2. Summary of Significant Accounting Policies

    Concentrations of Risks

    The Company’s revenue is reliant on its customers utilizing Internet-based services. These services can be prone to rapid changes in technology and government regulation. If the Company were unable to keep pace with customers’
    ###

    we want to be able to identify 'Note 2. Summary of Significant Accounting Policies' as title of the section and 'Concentrations of Risks' as subtitle of the section.


    Chunk text into maximum size chunks

3)  Extract tables separately as they are a very important source of numerical data

    Use tabula library to be able to convert tables into dataframes. Use spatial coordinates of tables to extract lines of text above said tables to provide context about tables' content.

4)  Ask question using Question Answering model for each table, gather answers and scores, keep highest scores and optionally aply score threshold.

5)  For top scores, add corresponding chunks into context of LLM and ask it to pick correct answer. Use answer logit to determine confidence, go to step 6 if too low.

6)  If score too low repeat 4 and 5 with text chunks, if answer confidence too low again raise flag


Toy example can be found in pdf_extraction.py file




